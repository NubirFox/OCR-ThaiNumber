{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = 'D:\\EN_ARIS4_2\\Proj_deep_learning\\Data_Grayscale'\n",
    "\n",
    "images = []\n",
    "labels = []\n",
    "\n",
    "folders = os.listdir(data)\n",
    "folders\n",
    "\n",
    "for folder in folders:\n",
    "    folder_path = os.path.join(data, folder)\n",
    "    for image_name in os.listdir(folder_path):\n",
    "        image_path = os.path.join(folder_path, image_name)\n",
    "        image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "        image = cv2.resize(image, (100, 100))\n",
    "        image = image.astype('float32') / 255.0\n",
    "\n",
    "        images.append(image)\n",
    "        labels.append(folder)\n",
    "\n",
    "images = np.array(images)\n",
    "images = np.expand_dims(images, axis=-1)\n",
    "\n",
    "print(f\"data value : {len(labels)}\")\n",
    "print(\"\")\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "encoded_labels = label_encoder.fit_transform(labels)\n",
    "print(f\"finish! label encoder\")\n",
    "print(\"\")\n",
    "X_train, X_test, y_train, y_test = train_test_split(images, encoded_labels, test_size=0.2, random_state=42)\n",
    "print(f\"finish! train test split\")\n",
    "print(\"\")\n",
    "\n",
    "def build_thai_ocr_model():\n",
    "    model = Sequential()\n",
    "\n",
    "    # Convolutional layers\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(100, 100, 1)))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    model.add(Conv2D(256, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    model.add(Flatten())\n",
    "\n",
    "    # Fully connected layers\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "\n",
    "    # Output layer (assuming the number of Thai characters in the dataset, adjust as needed)\n",
    "    model.add(Dense(len(folders), activation='softmax'))\n",
    "\n",
    "    return model\n",
    "\n",
    "model = build_thai_ocr_model()\n",
    "model.summary()\n",
    "\n",
    "model.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])\n",
    "print(\"finish! compile model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train, y_train, validation_data = (X_test, y_test), epochs = 100, batch_size = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "print(f'Test Accuracy: {test_acc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the training and validation accuracy\n",
    "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Plot the training and validation loss\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('v4.h5')\n",
    "print(\"Model saved as 'v4.h5'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to predict Thai character from a new image\n",
    "def predict_thai_character(image):\n",
    "    # Preprocess the image (resize to 95x95, normalize)\n",
    "    image = cv2.resize(image, (100, 100))\n",
    "    image = image.astype('float32') / 255.0\n",
    "    image = np.expand_dims(image, axis=(0, -1))\n",
    "\n",
    "    # Predict the character\n",
    "    prediction = model.predict(image)\n",
    "    predicted_class = np.argmax(prediction)\n",
    "\n",
    "    # Convert the integer back to the Thai character\n",
    "    predicted_label = label_encoder.inverse_transform([predicted_class])[0]\n",
    "    return predicted_label\n",
    "\n",
    "# Test the prediction function with a new image\n",
    "test_image = cv2.imread('captured_image.jpg', cv2.IMREAD_GRAYSCALE)\n",
    "cv2.imshow('image',test_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "predicted_thai_character = predict_thai_character(test_image)\n",
    "print(f'Predicted Thai character: {predicted_thai_character}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure, axis = plt.subplots(3, 4)\n",
    "\n",
    "i = 250\n",
    "\n",
    "zero = cv2.imread(f'Data_Grayscale/0/0({i})_0.jpg', cv2.IMREAD_GRAYSCALE)\n",
    "pred = predict_thai_character(zero)\n",
    "axis[0, 0].set_title(f'label : {pred}')\n",
    "axis[0, 0].imshow(zero)\n",
    "axis[0, 0].axis('off')\n",
    "\n",
    "zero = cv2.imread(f'Data_Grayscale/1/1({i})_0.jpg', cv2.IMREAD_GRAYSCALE)\n",
    "pred = predict_thai_character(zero)\n",
    "axis[0, 1].set_title(f'label : {pred}')\n",
    "axis[0, 1].imshow(zero)\n",
    "axis[0, 1].axis('off')\n",
    "\n",
    "zero = cv2.imread(f'Data_Grayscale/2/2({i})_0.jpg', cv2.IMREAD_GRAYSCALE)\n",
    "pred = predict_thai_character(zero)\n",
    "axis[0, 2].set_title(f'label : {pred}')\n",
    "axis[0, 2].imshow(zero)\n",
    "axis[0, 2].axis('off')\n",
    "\n",
    "zero = cv2.imread(f'Data_Grayscale/3/3({i})_0.jpg', cv2.IMREAD_GRAYSCALE)\n",
    "pred = predict_thai_character(zero)\n",
    "axis[0, 3].set_title(f'label : {pred}')\n",
    "axis[0, 3].imshow(zero)\n",
    "axis[0, 3].axis('off')\n",
    "\n",
    "zero = cv2.imread(f'Data_Grayscale/4/4({i})_0.jpg', cv2.IMREAD_GRAYSCALE)\n",
    "pred = predict_thai_character(zero)\n",
    "axis[1, 0].set_title(f'label : {pred}')\n",
    "axis[1, 0].imshow(zero)\n",
    "axis[1, 0].axis('off')\n",
    "\n",
    "zero = cv2.imread(f'Data_Grayscale/5/5({i})_0.jpg', cv2.IMREAD_GRAYSCALE)\n",
    "pred = predict_thai_character(zero)\n",
    "axis[1, 1].set_title(f'label : {pred}')\n",
    "axis[1, 1].imshow(zero)\n",
    "axis[1, 1].axis('off')\n",
    "\n",
    "zero = cv2.imread(f'Data_Grayscale/6/6({i})_0.jpg', cv2.IMREAD_GRAYSCALE)\n",
    "pred = predict_thai_character(zero)\n",
    "axis[1, 2].set_title(f'label : {pred}')\n",
    "axis[1, 2].imshow(zero)\n",
    "axis[1, 2].axis('off')\n",
    "\n",
    "zero = cv2.imread(f'Data_Grayscale/7/7({i})_0.jpg', cv2.IMREAD_GRAYSCALE)\n",
    "pred = predict_thai_character(zero)\n",
    "axis[1, 3].set_title(f'label : {pred}')\n",
    "axis[1, 3].imshow(zero)\n",
    "axis[1, 3].axis('off')\n",
    "\n",
    "zero = cv2.imread(f'Data_Grayscale/8/8({i})_0.jpg', cv2.IMREAD_GRAYSCALE)\n",
    "pred = predict_thai_character(zero)\n",
    "axis[2, 0].set_title(f'label : {pred}')\n",
    "axis[2, 0].imshow(zero)\n",
    "axis[2, 0].axis('off')\n",
    "\n",
    "zero = cv2.imread(f'Data_Grayscale/9/9({i})_0.jpg', cv2.IMREAD_GRAYSCALE)\n",
    "pred = predict_thai_character(zero)\n",
    "axis[2, 1].set_title(f'label : {pred}')\n",
    "axis[2, 1].imshow(zero)\n",
    "axis[2, 1].axis('off')\n",
    "\n",
    "zero = cv2.imread(f'Data_Grayscale/0/0({260})_0.jpg', cv2.IMREAD_GRAYSCALE)\n",
    "pred = predict_thai_character(zero)\n",
    "axis[2, 2].set_title(f'label : {pred}')\n",
    "axis[2, 2].imshow(zero)\n",
    "axis[2, 2].axis('off')\n",
    "\n",
    "zero = cv2.imread(f'Data_Grayscale/5/5({260})_0.jpg', cv2.IMREAD_GRAYSCALE)\n",
    "pred = predict_thai_character(zero)\n",
    "axis[2, 3].set_title(f'label : {pred}')\n",
    "axis[2, 3].imshow(zero)\n",
    "axis[2, 3].axis('off')\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
